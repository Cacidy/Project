{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Notice**  \n",
    "1. For data of volume, **Bitcon** data is incomplete, so we chose to eliminate the Bitcon in the volume section, and chose to plot the volume graph in the next place in the tvl order sort, i.e., the **Polygon**.  \n",
    "2. For the chainname obtained through the tvl sort is not completely correct, in the api of the fee and volume there are some chains can not get the data, we are here to eliminate these data.  \n",
    "3. We need data of 365*2+30 days (of tvl and price) to calculate the z-score to recognize abnormal values. We only plot data of 120 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         name           tvl\n",
      "16   Ethereum  5.698114e+10\n",
      "49     Solana  1.008245e+10\n",
      "56    Bitcoin  6.867289e+09\n",
      "94       Tron  5.649744e+09\n",
      "10        BSC  4.981577e+09\n",
      "17       Base  2.975321e+09\n",
      "19   Arbitrum  2.633880e+09\n",
      "97        Sui  1.474867e+09\n",
      "14  Avalanche  1.247957e+09\n",
      "22       CORE  8.917046e+08\n",
      "61      Aptos  8.571662e+08\n"
     ]
    }
   ],
   "source": [
    "# you can get the chain list straihgt from the API\n",
    "url = 'https://api.llama.fi/v2/chains'\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200: # data was fetched successfully\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "else:\n",
    "    raise Exception('Error fetching data from DeFiLlama API')\n",
    "\n",
    "dex_all_chains_url = \"https://api.llama.fi/overview/dexs?excludeTotalDataChart=true&excludeTotalDataChartBreakdown=true&dataType=dailyVolume\"\n",
    "dex_all_chains_response = requests.get(dex_all_chains_url)\n",
    "\n",
    "dex_all_chains_data = dex_all_chains_response.json()\n",
    "dex_all_chains = set(dex_all_chains_data.get('allChains', []))\n",
    "\n",
    "\n",
    "fees_all_chains_url = \"https://api.llama.fi/overview/fees?excludeTotalDataChart=true&excludeTotalDataChartBreakdown=true&dataType=dailyFees\"\n",
    "fees_all_chains_response = requests.get(fees_all_chains_url)\n",
    "\n",
    "fees_all_chains_data = fees_all_chains_response.json()\n",
    "fees_all_chains = set(fees_all_chains_data.get('allChains', []))\n",
    "\n",
    "common_chains = dex_all_chains.intersection(fees_all_chains) # get the common chains between the two sets\n",
    "\n",
    "df = df[['name', 'tvl']]\n",
    "df = df[df['name'].isin(common_chains)]\n",
    "\n",
    "# Sort the data to get the top 10 chains by TVL\n",
    "df = df.sort_values(by='tvl', ascending=False).head(11)\n",
    "print(df)\n",
    "\n",
    "# build the folder structure, update data\n",
    "base_folder = './data'\n",
    "fee_folder = os.path.join(base_folder, 'fee')\n",
    "tvl_folder = os.path.join(base_folder, 'tvl')\n",
    "volume_folder = os.path.join(base_folder, 'volume')\n",
    "price_folder = os.path.join(base_folder, 'price')\n",
    "\n",
    "for folder in [fee_folder, tvl_folder, volume_folder, price_folder]:\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder)  # delete the folder and its contents\n",
    "    os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_order = df['name'].tolist()\n",
    "chain_index = {chain: str(index + 1).zfill(2) for index, chain in enumerate(chain_order)}\n",
    "# give chainname an index so we can plot in order\n",
    "\n",
    "\n",
    "def fetch_historical_data(chain_name, metric):\n",
    "    if metric == 'tvl':\n",
    "        url = f'https://api.llama.fi/v2/historicalChainTvl/{chain_name}'\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data)  # Directly create DataFrame from the list of dictionaries\n",
    "            df['date'] = pd.to_datetime(df['date'], unit='s')\n",
    "            csv_filename = os.path.join(tvl_folder, f\"{chain_index[chain_name]}_{chain_name}_{metric}.csv\")\n",
    "            df = df[['date', metric]].tail(365*2+30)\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(f\"Saved {metric} data for {chain_name} to {csv_filename}\")\n",
    "        else:\n",
    "            raise Exception(f'Error fetching historical {metric} data for {chain_name}')\n",
    "        \n",
    "    elif metric == 'volume':\n",
    "        url = (f'https://api.llama.fi/overview/dexs/{chain_name}'\n",
    "                  '?excludeTotalDataChart=false'\n",
    "                  '&excludeTotalDataChartBreakdown=true'\n",
    "                  '&dataType=dailyVolume')\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data['totalDataChart'], columns=['timestamp', metric])   \n",
    "            df['date'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "            df = df.sort_values(by='date')\n",
    "            df = df[['date', metric]].tail(365*2+30)\n",
    "            csv_filename = os.path.join(volume_folder, f\"{chain_index[chain_name]}_{chain_name}_{metric}.csv\")\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(f\"Saved {metric} data for {chain_name} to {csv_filename}\")\n",
    "        else:\n",
    "            raise Exception(f'Error fetching historical {metric} data for {chain_name}')\n",
    "        \n",
    "    elif metric == 'fee':\n",
    "        url = (f'https://api.llama.fi/overview/fees/{chain_name}'\n",
    "                  '?excludeTotalDataChart=false'\n",
    "                  '&excludeTotalDataChartBreakdown=true'\n",
    "                  '&dataType=dailyFees')\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data['totalDataChart'], columns=['timestamp', metric])   \n",
    "            df['date'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "            df = df.sort_values(by='date')\n",
    "            df = df[['date', metric]].tail(365*2+30)\n",
    "            csv_filename = os.path.join(fee_folder, f\"{chain_index[chain_name]}_{chain_name}_{metric}.csv\")\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(f\"Saved {metric} data for {chain_name} to {csv_filename}\")\n",
    "        else:\n",
    "            raise Exception(f'Error fetching historical {metric} data for {chain_name}')\n",
    "    else:\n",
    "        raise ValueError('Invalid metric specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import getpass\n",
    "# find a way to use relative path, so that the function in dynamoUtil can be run in any machine\n",
    "src_path = r'C:\\Users\\YuweiCao\\Documents\\GitHub\\char-python-common\\src'\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "USER = getpass.getuser()\n",
    "REPO_PATH = r'C:\\Users\\YuweiCao\\Documents\\GitHub\\char-python-common'\n",
    "\n",
    "sys.path.append(REPO_PATH)\n",
    "sys.path.append(REPO_PATH + '/src')\n",
    "\n",
    "from dynamoUtil import price_bar_query\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "mapping = {\n",
    "    'Ethereum': 'ETHUSDT-OKX-00000000-FUT',\n",
    "    'Tron': 'TRXUSDT-OKX-00000000-FUT',\n",
    "    'Solana': 'SOLUSDT-OKX-00000000-FUT',\n",
    "    'BSC': 'BNBUSDT-OKX-00000000-FUT',\n",
    "    'Base': 'BASEUSDT-OKX-00000000-FUT',\n",
    "    'Bitcoin': 'BTCUSDT-OKX-00000000-FUT',\n",
    "    'Arbitrum': 'ARBUSDT-OKX-00000000-FUT',\n",
    "    'Avalanche': 'AVAXUSDT-OKX-00000000-FUT',\n",
    "    'Sui': 'SUIUSDT-OKX-00000000-FUT',\n",
    "    'Aptos': 'APTUSDT-OKX-00000000-FUT',\n",
    "    'Polygon': 'MATICUSDT-OKX-00000000-FUT'\n",
    "}\n",
    "\n",
    "# give df the mapping of the code\n",
    "'''\n",
    "    直接用map list对应不知道会不会有问题\n",
    "'''\n",
    "\n",
    "def fetch_price_data(chain_name):\n",
    "    today = datetime.now().replace(hour=23, minute=0, second=0, microsecond=0)\n",
    "    start_date = today - timedelta(days=365*2+30)\n",
    "\n",
    "    today_str = today.strftime('%Y-%m-%d-%H-%M')\n",
    "    start_date_str = start_date.strftime('%Y-%m-%d-%H-%M')\n",
    "    \n",
    "    instrument_code = mapping.get(chain_name)\n",
    "\n",
    "    price_data = price_bar_query(instrument_code + '|1440', start_date_str, today_str, 'live')\n",
    "    price_df = pd.DataFrame(price_data)\n",
    "    print(f\"Columns in DataFrame for {chain_name}: {price_df.columns}\") \n",
    "    print(price_df.head())\n",
    "    \n",
    "    if price_df.empty:\n",
    "        print(f\"No valid data found for {chain_name}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    if 'timestamp' not in price_df.columns or 'close' not in price_df.columns:\n",
    "        print(f\"Required columns 'timestamp' or 'close' not found in the data for {chain_name}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    selected_columns = price_df[['timestamp', 'close']].copy()\n",
    "\n",
    "    selected_columns['timestamp'] = pd.to_datetime(selected_columns['timestamp']).dt.date\n",
    "\n",
    "    selected_columns.rename(columns={'timestamp': 'date', 'close': 'price'}, inplace=True)\n",
    "\n",
    "    csv_filename = os.path.join(price_folder, f\"{chain_index[chain_name]}_{chain_name}_price.csv\")\n",
    "    # csv_filename = os.path.join(price_folder_USD, f\"{chain_index[chain_name]}_{chain_name}_price_USD.csv\")\n",
    "    selected_columns.to_csv(csv_filename, index=False)\n",
    "    print(f\"Saved price data for {chain_name} to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.For tvl we store all 11 of them.  \n",
    "2.For volume we skip Bitcoin, it's incomplete.  \n",
    "3.For fee we store all 11 of them.\n",
    "4.For price we skip Base(doesn't have coin), store POL and TRX using api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tvl data for Ethereum to ./data\\tvl\\01_Ethereum_tvl.csv\n",
      "Saved fee data for Ethereum to ./data\\fee\\01_Ethereum_fee.csv\n",
      "Saved tvl data for Solana to ./data\\tvl\\02_Solana_tvl.csv\n",
      "Saved fee data for Solana to ./data\\fee\\02_Solana_fee.csv\n",
      "Saved tvl data for Bitcoin to ./data\\tvl\\03_Bitcoin_tvl.csv\n",
      "Saved fee data for Bitcoin to ./data\\fee\\03_Bitcoin_fee.csv\n",
      "Saved tvl data for Tron to ./data\\tvl\\04_Tron_tvl.csv\n",
      "Saved fee data for Tron to ./data\\fee\\04_Tron_fee.csv\n",
      "Saved tvl data for BSC to ./data\\tvl\\05_BSC_tvl.csv\n",
      "Saved fee data for BSC to ./data\\fee\\05_BSC_fee.csv\n",
      "Saved tvl data for Base to ./data\\tvl\\06_Base_tvl.csv\n",
      "Saved fee data for Base to ./data\\fee\\06_Base_fee.csv\n",
      "Saved tvl data for Arbitrum to ./data\\tvl\\07_Arbitrum_tvl.csv\n",
      "Saved fee data for Arbitrum to ./data\\fee\\07_Arbitrum_fee.csv\n",
      "Saved tvl data for Sui to ./data\\tvl\\08_Sui_tvl.csv\n",
      "Saved fee data for Sui to ./data\\fee\\08_Sui_fee.csv\n",
      "Saved tvl data for Avalanche to ./data\\tvl\\09_Avalanche_tvl.csv\n",
      "Saved fee data for Avalanche to ./data\\fee\\09_Avalanche_fee.csv\n",
      "Saved tvl data for CORE to ./data\\tvl\\10_CORE_tvl.csv\n",
      "Saved fee data for CORE to ./data\\fee\\10_CORE_fee.csv\n",
      "Saved tvl data for Aptos to ./data\\tvl\\11_Aptos_tvl.csv\n",
      "Saved fee data for Aptos to ./data\\fee\\11_Aptos_fee.csv\n",
      "Saved volume data for Ethereum to ./data\\volume\\01_Ethereum_volume.csv\n",
      "Saved volume data for Solana to ./data\\volume\\02_Solana_volume.csv\n",
      "Skipping Bitcoin for volume\n",
      "Saved volume data for Tron to ./data\\volume\\04_Tron_volume.csv\n",
      "Saved volume data for BSC to ./data\\volume\\05_BSC_volume.csv\n",
      "Saved volume data for Base to ./data\\volume\\06_Base_volume.csv\n",
      "Saved volume data for Arbitrum to ./data\\volume\\07_Arbitrum_volume.csv\n",
      "Saved volume data for Sui to ./data\\volume\\08_Sui_volume.csv\n",
      "Saved volume data for Avalanche to ./data\\volume\\09_Avalanche_volume.csv\n",
      "Saved volume data for CORE to ./data\\volume\\10_CORE_volume.csv\n",
      "Saved volume data for Aptos to ./data\\volume\\11_Aptos_volume.csv\n",
      "Columns in DataFrame for Ethereum: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "       low      updatedAt  timestamp     open    volume     high    close  \\\n",
      "0     1261  1673222328312 2023-01-07  1270.32   5933532  1270.63   1263.8   \n",
      "1  1259.03  1673308730957 2023-01-08  1261.04  14243959     1298  1290.07   \n",
      "2  1288.44  1673395038444 2023-01-09  1294.97  35620462  1344.49   1320.4   \n",
      "3  1316.72  1673481286544 2023-01-10  1327.68  19836150  1348.46  1335.16   \n",
      "4     1321  1673567884635 2023-01-11   1337.3  24683385  1408.43  1389.66   \n",
      "\n",
      "                 instrument  \n",
      "0  ETHUSDT-OKX-00000000-FUT  \n",
      "1  ETHUSDT-OKX-00000000-FUT  \n",
      "2  ETHUSDT-OKX-00000000-FUT  \n",
      "3  ETHUSDT-OKX-00000000-FUT  \n",
      "4  ETHUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Ethereum to ./data\\price\\01_Ethereum_price.csv\n",
      "Columns in DataFrame for Solana: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "      low      updatedAt  timestamp    open    volume    high   close  \\\n",
      "0  13.011  1673222002540 2023-01-07  13.443   6758031  13.473  13.095   \n",
      "1  12.888  1673308405099 2023-01-08  12.909  19908333  14.988  14.468   \n",
      "2  14.714  1673395178978 2023-01-09  14.956  38462333  17.493  16.276   \n",
      "3  15.532  1673481426366 2023-01-10  16.578  19630239  16.752    16.2   \n",
      "4   15.27  1673567559438 2023-01-11   16.16  14466039  16.616  16.364   \n",
      "\n",
      "                 instrument  \n",
      "0  SOLUSDT-OKX-00000000-FUT  \n",
      "1  SOLUSDT-OKX-00000000-FUT  \n",
      "2  SOLUSDT-OKX-00000000-FUT  \n",
      "3  SOLUSDT-OKX-00000000-FUT  \n",
      "4  SOLUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Solana to ./data\\price\\02_Solana_price.csv\n",
      "Columns in DataFrame for Bitcoin: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "       low      updatedAt  timestamp     open   volume     high    close  \\\n",
      "0  16910.7  1673222208817 2023-01-07  16976.1  1382745  16981.2  16946.8   \n",
      "1  16915.1  1673308611361 2023-01-08  16925.7  3184015  17189.5  17129.9   \n",
      "2    17130  1673394918987 2023-01-09  17186.9  7140506  17399.7  17180.9   \n",
      "3  17151.8  1673481167351 2023-01-10  17221.6  5341206  17487.9    17437   \n",
      "4  17319.9  1673567765121 2023-01-11    17464  7079374  18005.3    17943   \n",
      "\n",
      "                 instrument  \n",
      "0  BTCUSDT-OKX-00000000-FUT  \n",
      "1  BTCUSDT-OKX-00000000-FUT  \n",
      "2  BTCUSDT-OKX-00000000-FUT  \n",
      "3  BTCUSDT-OKX-00000000-FUT  \n",
      "4  BTCUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Bitcoin to ./data\\price\\03_Bitcoin_price.csv\n",
      "Columns in DataFrame for Tron: RangeIndex(start=0, stop=0, step=1)\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "No valid data found for Tron. Skipping.\n",
      "Columns in DataFrame for BSC: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "      low      updatedAt  timestamp    open   volume    high   close  \\\n",
      "0  259.69  1673222197981 2023-01-07  263.23  1618957  263.23  261.06   \n",
      "1  260.07  1673308600530 2023-01-08  260.39  4114493  276.98     275   \n",
      "2  271.25  1673394908128 2023-01-09  278.56  4387978  283.76  272.58   \n",
      "3  270.09  1673481156511 2023-01-10  276.09  2731282  278.69   276.9   \n",
      "4  273.98  1673567754349 2023-01-11  276.73  4292628  287.88  284.79   \n",
      "\n",
      "                 instrument  \n",
      "0  BNBUSDT-OKX-00000000-FUT  \n",
      "1  BNBUSDT-OKX-00000000-FUT  \n",
      "2  BNBUSDT-OKX-00000000-FUT  \n",
      "3  BNBUSDT-OKX-00000000-FUT  \n",
      "4  BNBUSDT-OKX-00000000-FUT  \n",
      "Saved price data for BSC to ./data\\price\\05_BSC_price.csv\n",
      "Columns in DataFrame for Base: RangeIndex(start=0, stop=0, step=1)\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "No valid data found for Base. Skipping.\n",
      "Columns in DataFrame for Arbitrum: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "      low      updatedAt  timestamp    open    volume    high   close  \\\n",
      "0   1.907  1709337514445 2024-02-29  1.9849   9460541  2.0959  1.9446   \n",
      "1  1.9405  1709423987133 2024-03-01  1.9764   4431391  2.0139  1.9893   \n",
      "2  1.9501  1709510224231 2024-03-02  1.9989   5307069  2.0268  2.0267   \n",
      "3  1.8044  1709596760522 2024-03-03  2.0991  12997647   2.198  2.0456   \n",
      "4  1.9201  1709682788112 2024-03-04  2.0324   7721973  2.0458   1.983   \n",
      "\n",
      "                 instrument  \n",
      "0  ARBUSDT-OKX-00000000-FUT  \n",
      "1  ARBUSDT-OKX-00000000-FUT  \n",
      "2  ARBUSDT-OKX-00000000-FUT  \n",
      "3  ARBUSDT-OKX-00000000-FUT  \n",
      "4  ARBUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Arbitrum to ./data\\price\\07_Arbitrum_price.csv\n",
      "Columns in DataFrame for Sui: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "      low      updatedAt  timestamp    open     volume    high   close  \\\n",
      "0  1.2321  1705362881490 2024-01-14  1.2687  177530154  1.3538  1.2511   \n",
      "1  1.2661  1705449301147 2024-01-15  1.2688  310876605  1.4513  1.3718   \n",
      "2  1.2396  1705535863976 2024-01-16  1.3716  198941899  1.3938  1.2706   \n",
      "3  1.1995  1705622210000 2024-01-17  1.3011  182543109  1.3291  1.2934   \n",
      "4  1.1443  1705708544738 2024-01-18   1.315  205568822  1.3482  1.1585   \n",
      "\n",
      "                 instrument  \n",
      "0  SUIUSDT-OKX-00000000-FUT  \n",
      "1  SUIUSDT-OKX-00000000-FUT  \n",
      "2  SUIUSDT-OKX-00000000-FUT  \n",
      "3  SUIUSDT-OKX-00000000-FUT  \n",
      "4  SUIUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Sui to ./data\\price\\08_Sui_price.csv\n",
      "Columns in DataFrame for Avalanche: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "     low      updatedAt  timestamp   open   volume   high  close  \\\n",
      "0  11.64  1673222132955 2023-01-07  11.84   381479  11.87  11.74   \n",
      "1  11.59  1673308535856 2023-01-08  11.65   602950  12.15  12.09   \n",
      "2  12.07  1673394842818 2023-01-09  12.37  2039162  12.65  12.18   \n",
      "3  12.01  1673481556655 2023-01-10  12.37  1628977  12.95  12.72   \n",
      "4  12.25  1673567689274 2023-01-11   12.7  7754541  16.05  15.83   \n",
      "\n",
      "                  instrument  \n",
      "0  AVAXUSDT-OKX-00000000-FUT  \n",
      "1  AVAXUSDT-OKX-00000000-FUT  \n",
      "2  AVAXUSDT-OKX-00000000-FUT  \n",
      "3  AVAXUSDT-OKX-00000000-FUT  \n",
      "4  AVAXUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Avalanche to ./data\\price\\09_Avalanche_price.csv\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     fetch_historical_data(chain_name, metric)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chain_name \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m---> 13\u001b[0m     fetch_price_data(chain_name)\n",
      "Cell \u001b[1;32mIn[4], line 47\u001b[0m, in \u001b[0;36mfetch_price_data\u001b[1;34m(chain_name)\u001b[0m\n\u001b[0;32m     43\u001b[0m start_date_str \u001b[38;5;241m=\u001b[39m start_date\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     45\u001b[0m instrument_code \u001b[38;5;241m=\u001b[39m mapping\u001b[38;5;241m.\u001b[39mget(chain_name)\n\u001b[1;32m---> 47\u001b[0m price_data \u001b[38;5;241m=\u001b[39m price_bar_query(instrument_code \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|1440\u001b[39m\u001b[38;5;124m'\u001b[39m, start_date_str, today_str, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     48\u001b[0m price_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(price_data)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns in DataFrame for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchain_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprice_df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "for chain_name in df['name']:\n",
    "    for metric in ['tvl', 'fee']:\n",
    "        fetch_historical_data(chain_name, metric)\n",
    "        \n",
    "for chain_name in df['name']:\n",
    "    if chain_name.lower() == 'bitcoin':\n",
    "        print(f\"Skipping {chain_name} for {metric}\")\n",
    "        continue # Skip Bitcoin as its volume data is incomplete\n",
    "    metric = 'volume'\n",
    "    fetch_historical_data(chain_name, metric)\n",
    "    \n",
    "for chain_name in df['name']:\n",
    "    fetch_price_data(chain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 03_Tron_price.csv\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://data-api.cryptocompare.com/futures/v1/historical/days\"\n",
    "params_trx = {\n",
    "    'market': 'okex', \n",
    "    'instrument': 'TRX-USDT-VANILLA-PERPETUAL', \n",
    "    'groups': 'OHLC',  \n",
    "    'limit': 365*2+30,  \n",
    "    'aggregate': 1,  \n",
    "    'fill': 'true',  \n",
    "    'apply_mapping': 'true',  \n",
    "    'api_key': 'YOUR_API_KEY'  \n",
    "}\n",
    "\n",
    "response_trx = requests.get(base_url, params=params_trx)\n",
    "\n",
    "if response_trx.status_code == 200:\n",
    "    data = response_trx.json()\n",
    "    if 'Data' in data and isinstance(data['Data'], list):\n",
    "        data_list = data['Data']\n",
    "\n",
    "        extracted_data = [{'timestamp': entry['TIMESTAMP'], 'price': entry['CLOSE']}\n",
    "                          for entry in data_list if 'TIMESTAMP' in entry and 'CLOSE' in entry]\n",
    "\n",
    "        df = pd.DataFrame(extracted_data)\n",
    "\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s').dt.date\n",
    "\n",
    "        df.rename(columns={'timestamp': 'date'}, inplace=True)\n",
    "\n",
    "        if not df.empty:\n",
    "            csv_filename = os.path.join(price_folder, \"03_Tron_price.csv\")\n",
    "            df.tail(150).to_csv(csv_filename, index=False)\n",
    "            print(\"Data saved to 03_Tron_price.csv\")\n",
    "        else:\n",
    "            print(\"No data available for TRX-USDT on OKEx (OKX).\")\n",
    "    else:\n",
    "        print(f\"Unexpected data format: {data}\")\n",
    "else:\n",
    "    print(f\"Failed to fetch data. HTTP status code: {response_trx.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data entry: {'UNIT': 'DAY', 'TIMESTAMP': 1727136000, 'TYPE': '914', 'MARKET': 'okex', 'INSTRUMENT': 'POL-USDT-SWAP', 'MAPPED_INSTRUMENT': 'POL-USDT-VANILLA-PERPETUAL', 'INDEX_UNDERLYING': 'POL', 'QUOTE_CURRENCY': 'USDT', 'SETTLEMENT_CURRENCY': 'USDT', 'CONTRACT_CURRENCY': 'POL', 'DENOMINATION_TYPE': 'VANILLA', 'INDEX_UNDERLYING_ID': 10343, 'QUOTE_CURRENCY_ID': 7, 'SETTLEMENT_CURRENCY_ID': 7, 'CONTRACT_CURRENCY_ID': 10343, 'TRANSFORM_FUNCTION': '', 'OPEN': 0.417, 'HIGH': 0.417, 'LOW': 0.3905, 'CLOSE': 0.4096, 'FIRST_TRADE_TIMESTAMP': 1727166616, 'LAST_TRADE_TIMESTAMP': 1727222160, 'FIRST_TRADE_PRICE': 0.417, 'HIGH_TRADE_PRICE': 0.417, 'HIGH_TRADE_TIMESTAMP': 1727166616, 'LOW_TRADE_PRICE': 0.3905, 'LOW_TRADE_TIMESTAMP': 1727166616, 'LAST_TRADE_PRICE': 0.4096, 'TOTAL_TRADES': 5847, 'TOTAL_TRADES_BUY': 3503, 'TOTAL_TRADES_SELL': 2344, 'TOTAL_TRADES_UNKNOWN': 0, 'NUMBER_OF_CONTRACTS': 363952, 'VOLUME': 3639520, 'QUOTE_VOLUME': 1479825.706, 'VOLUME_BUY': 1766230, 'QUOTE_VOLUME_BUY': 718157.133, 'VOLUME_SELL': 1873290, 'QUOTE_VOLUME_SELL': 761668.573, 'VOLUME_UNKNOWN': 0, 'QUOTE_VOLUME_UNKNOWN': 0}\n",
      "Failed to fetch data. HTTP status code: 404\n",
      "Fail to fetch enough data.\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://data-api.cryptocompare.com/futures/v1/historical/days\"\n",
    "api_key = \"YOUR_API_KEY\"\n",
    "\n",
    "today_timestamp = int(time.time()) \n",
    "\n",
    "params_1 = {\n",
    "    \"market\": \"okex\",\n",
    "    \"instrument\": \"POL-USDT-VANILLA-PERPETUAL\",\n",
    "    \"limit\": 365*2+30,\n",
    "    \"aggregate\": 1,\n",
    "    \"fill\": \"true\",\n",
    "    \"apply_mapping\": \"true\",\n",
    "    \"to_ts\": today_timestamp, \n",
    "    \"api_key\": api_key\n",
    "}\n",
    "\n",
    "params_2 = {\n",
    "    \"market\": \"bitmex\",\n",
    "    \"instrument\": \"MATIC-USDT-VANILLA-PERPETUAL\",\n",
    "    \"limit\": 365*2+30,\n",
    "    \"aggregate\": 1,\n",
    "    \"fill\": \"true\",\n",
    "    \"apply_mapping\": \"true\",\n",
    "    \"to_ts\": 1727062614,  \n",
    "    \"api_key\": api_key\n",
    "}\n",
    "\n",
    "def fetch_data(params):\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if 'Data' in data and isinstance(data['Data'], list):\n",
    "            data_list = data['Data']\n",
    "\n",
    "            if not data_list:\n",
    "                print(\"No data returned.\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            print(\"Sample data entry:\", data_list[0])  \n",
    "\n",
    "            extracted_data = []\n",
    "            for entry in data_list:\n",
    "                if 'TIMESTAMP' in entry and 'CLOSE' in entry: \n",
    "                    extracted_data.append({\n",
    "                        'timestamp': entry['TIMESTAMP'], \n",
    "                        'price': entry['CLOSE']\n",
    "                    })\n",
    "                else:\n",
    "                    print(\"Missing expected fields in entry:\", entry)\n",
    "\n",
    "            if not extracted_data:\n",
    "                print(\"No valid data extracted.\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            df = pd.DataFrame(extracted_data)\n",
    "\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s').dt.date\n",
    "\n",
    "            df.rename(columns={'timestamp': 'date'}, inplace=True)\n",
    "\n",
    "            return df\n",
    "        else:\n",
    "            print(\"Unexpected data format:\", data)\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data. HTTP status code: {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "data_1 = fetch_data(params_1)\n",
    "data_2 = fetch_data(params_2)\n",
    "\n",
    "if not data_1.empty and not data_2.empty:\n",
    "    combined_data = pd.concat([data_1, data_2]).drop_duplicates(subset=[\"date\"], keep=\"last\") # combine and remove duplicates\n",
    "    combined_data.sort_values(by=\"date\", inplace=True)\n",
    "\n",
    "    combined_data = combined_data.tail(365*2+30)\n",
    "    csv_filename = os.path.join(price_folder, f\"11_Polygon_price.csv\")\n",
    "    combined_data.to_csv(csv_filename, index=False)\n",
    "    print(\"Data saved to 11_Polygon_price.csv\")\n",
    "else:\n",
    "    print(\"Fail to fetch enough data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
