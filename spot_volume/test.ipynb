{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cryptocompare  \n",
    "https://developers.cryptocompare.com/documentation/data-api/spot_v1_historical_hours\n",
    "biance,bybit,okx,bitget,coinbase,kraken,upbit,gateio,bitfinex,gemini,binanceusa,bingx,bitmex,bitstamp,coinbaseinternational,kucoin,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "API_KEY = \"83b1fe1bf4762e0bfb056afa64f89b227988cd131d26ee0ff465b9c3a7070e19\" # cryptocompare api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 获取 176 个交易所\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>EXCHANGE_STATUS</th>\n",
       "      <th>MAPPED_INSTRUMENTS_TOTAL</th>\n",
       "      <th>UNMAPPED_INSTRUMENTS_TOTAL</th>\n",
       "      <th>INSTRUMENT_STATUS</th>\n",
       "      <th>TOTAL_TRADES_SPOT</th>\n",
       "      <th>HAS_ORDERBOOK_L2_MINUTE_SNAPSHOTS_ENABLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aax</td>\n",
       "      <td>602</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>250</td>\n",
       "      <td>185</td>\n",
       "      <td>{'ACTIVE': 88, 'IGNORED': 0, 'RETIRED': 347, '...</td>\n",
       "      <td>648891006</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abcc</td>\n",
       "      <td>602</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>304</td>\n",
       "      <td>28</td>\n",
       "      <td>{'ACTIVE': 29, 'IGNORED': 0, 'RETIRED': 303, '...</td>\n",
       "      <td>8437466</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acx</td>\n",
       "      <td>602</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>{'ACTIVE': 32, 'IGNORED': 0, 'RETIRED': 0, 'EX...</td>\n",
       "      <td>6203612</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aidosmarket</td>\n",
       "      <td>602</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'ACTIVE': 2, 'IGNORED': 0, 'RETIRED': 1, 'EXP...</td>\n",
       "      <td>155608</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alphaex</td>\n",
       "      <td>602</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>{'ACTIVE': 2, 'IGNORED': 0, 'RETIRED': 10, 'EX...</td>\n",
       "      <td>1718824</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        market TYPE EXCHANGE_STATUS  MAPPED_INSTRUMENTS_TOTAL  \\\n",
       "0          aax  602          ACTIVE                       250   \n",
       "1         abcc  602          ACTIVE                       304   \n",
       "2          acx  602          ACTIVE                         0   \n",
       "3  aidosmarket  602          ACTIVE                         1   \n",
       "4      alphaex  602          ACTIVE                        10   \n",
       "\n",
       "   UNMAPPED_INSTRUMENTS_TOTAL  \\\n",
       "0                         185   \n",
       "1                          28   \n",
       "2                          32   \n",
       "3                           2   \n",
       "4                           2   \n",
       "\n",
       "                                   INSTRUMENT_STATUS  TOTAL_TRADES_SPOT  \\\n",
       "0  {'ACTIVE': 88, 'IGNORED': 0, 'RETIRED': 347, '...          648891006   \n",
       "1  {'ACTIVE': 29, 'IGNORED': 0, 'RETIRED': 303, '...            8437466   \n",
       "2  {'ACTIVE': 32, 'IGNORED': 0, 'RETIRED': 0, 'EX...            6203612   \n",
       "3  {'ACTIVE': 2, 'IGNORED': 0, 'RETIRED': 1, 'EXP...             155608   \n",
       "4  {'ACTIVE': 2, 'IGNORED': 0, 'RETIRED': 10, 'EX...            1718824   \n",
       "\n",
       "   HAS_ORDERBOOK_L2_MINUTE_SNAPSHOTS_ENABLED  \n",
       "0                                      False  \n",
       "1                                      False  \n",
       "2                                      False  \n",
       "3                                      False  \n",
       "4                                      False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_markets = \"https://data-api.cryptocompare.com/spot/v1/markets\"\n",
    "\n",
    "headers = {\"Content-type\": \"application/json\", \"authorization\": f\"Apikey {API_KEY}\"}\n",
    "response = requests.get(url_markets, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()[\"Data\"]\n",
    "\n",
    "    # **提取所有 market（交易所）**\n",
    "    markets = [{\"market\": market, **details} for market, details in data.items()]\n",
    "    markets_df = pd.DataFrame(markets)\n",
    "    print(f\"✅ 获取 {len(markets_df)} 个交易所\")\n",
    "\n",
    "else:\n",
    "    print(f\"❌ API 请求失败: {response.status_code}, {response.text}\")\n",
    "\n",
    "markets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_markets = [\n",
    "    \"binance\", \"binanceaggregate\", \"binanceusa\", \"bingx\", \"bitfinex\",\n",
    "    \"bitget\", \"bitmex\", \"bitstamp\", \"bybit\", \"coinbase\",\n",
    "    \"coinbaseinternational\", \"gateio\", \"gemini\", \"kraken\", \"kucoin\",\n",
    "    \"okx\", \"upbit\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ binance 交易所的 1344 个交易对已获取\n",
      "✅ binanceaggregate 交易所的 1344 个交易对已获取\n",
      "✅ binanceusa 交易所的 183 个交易对已获取\n",
      "✅ bingx 交易所的 883 个交易对已获取\n",
      "✅ bitfinex 交易所的 285 个交易对已获取\n",
      "✅ bitget 交易所的 806 个交易对已获取\n",
      "✅ bitmex 交易所的 16 个交易对已获取\n",
      "✅ bitstamp 交易所的 244 个交易对已获取\n",
      "✅ bybit 交易所的 610 个交易对已获取\n",
      "✅ coinbase 交易所的 432 个交易对已获取\n",
      "✅ coinbaseinternational 交易所的 2 个交易对已获取\n",
      "✅ gateio 交易所的 2579 个交易对已获取\n",
      "✅ gemini 交易所的 102 个交易对已获取\n",
      "✅ kraken 交易所的 867 个交易对已获取\n",
      "✅ kucoin 交易所的 1080 个交易对已获取\n",
      "✅ okx 交易所的 0 个交易对已获取\n",
      "✅ upbit 交易所的 429 个交易对已获取\n"
     ]
    }
   ],
   "source": [
    "url_instruments = \"https://data-api.cryptocompare.com/spot/v1/markets/instruments\"\n",
    "headers = {\"Content-type\": \"application/json\", \"authorization\": f\"Apikey {API_KEY}\"}\n",
    "\n",
    "all_instruments = []\n",
    "\n",
    "for market in selected_markets:\n",
    "    params = {\"market\": market}\n",
    "    response = requests.get(url_instruments, headers=headers, params=params)\n",
    "\n",
    "    json_response = response.json()\n",
    "    market_data = json_response[\"Data\"].get(market, {})\n",
    "    instruments_data = market_data.get(\"instruments\", {})\n",
    "\n",
    "    # 遍历market的所有交易对\n",
    "    for instrument_name, instrument_details in instruments_data.items():\n",
    "        all_instruments.append({\n",
    "            \"market\": market,\n",
    "            \"instrument\": instrument_name,\n",
    "            \"base_asset\": instrument_details.get(\"INSTRUMENT\", \"N/A\"),\n",
    "            \"status\": instrument_details.get(\"INSTRUMENT_STATUS\", \"UNKNOWN\")\n",
    "        })\n",
    "\n",
    "    print(f\"✅ {market} 交易所的 {len(instruments_data)} 个交易对已获取\")\n",
    "\n",
    "    # 避免过快请求\n",
    "    time.sleep(0.5)\n",
    "\n",
    "instruments_df = pd.DataFrame(all_instruments)\n",
    "instruments_df.head()\n",
    "\n",
    "save_dir = \"C:/Users/YuweiCao/Documents/GitHub/Project/Project/spot_volume/result\"\n",
    "csv_filepath = os.path.join(save_dir, \"crypto_instruments.csv\")\n",
    "instruments_df.to_csv(csv_filepath, index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data successfully fetched: binance - MANA-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - VOXEL-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - AUDIO-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - JST-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - MBL-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - BEL-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - APT-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - PAXG-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - ETH-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - QKC-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - MOVR-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - BLUR-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - LSK-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - VIC-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - FIL-FDUSD (2000 hours)\n",
      "✅ Data successfully fetched: binance - ANKR-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - UMA-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - SEI-BNB (2000 hours)\n",
      "✅ Data successfully fetched: binance - XLM-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - OXT-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - XVS-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - SEI-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - NEO-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - BCH-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - SFP-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - XRP-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - ADA-ETH (2000 hours)\n",
      "✅ Data successfully fetched: binance - CFX-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - LOKA-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - EDU-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - LEVER-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - SHIB-EUR (2000 hours)\n",
      "✅ Data successfully fetched: binance - BEAM-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - AR-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - AVAX-FDUSD (2000 hours)\n",
      "✅ Data successfully fetched: binance - AST-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - FDUSD-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - XLM-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - XEC-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - BSW-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - BADGER-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - DUSK-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - ACM-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - ARB-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - GMT-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - NFP-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - POLYX-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - ADX-ETH (2000 hours)\n",
      "✅ Data successfully fetched: binance - VIB-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - ARB-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - GALA-BNB (2000 hours)\n",
      "✅ Data successfully fetched: binance - DOGE-TUSD (2000 hours)\n",
      "✅ Data successfully fetched: binance - SOL-TUSD (2000 hours)\n",
      "✅ Data successfully fetched: binance - YGG-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - TIA-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - PROM-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - CELR-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - KAVA-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - DYDX-FDUSD (2000 hours)\n",
      "✅ Data successfully fetched: binance - ALPHA-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - DOT-USDC (2000 hours)\n",
      "✅ Data successfully fetched: binance - DYDX-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - SC-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - PYR-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - ARDR-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - GALA-BRL (2000 hours)\n",
      "✅ Data successfully fetched: binance - ARB-EUR (2000 hours)\n",
      "✅ Data successfully fetched: binance - RPL-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - LUNC-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - WBTC-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - LINK-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - SEI-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - ONT-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - YFI-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - CAKE-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - DGB-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - LRC-ETH (2000 hours)\n",
      "✅ Data successfully fetched: binance - USDP-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - ETH-FDUSD (2000 hours)\n",
      "✅ Data successfully fetched: binance - ACA-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - GAS-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - ETH-EUR (2000 hours)\n",
      "✅ Data successfully fetched: binance - HOT-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - OP-FDUSD (2000 hours)\n",
      "✅ Data successfully fetched: binance - CVX-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - GRT-ETH (2000 hours)\n",
      "✅ Data successfully fetched: binance - STEEM-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - XLM-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - SSV-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - BONK-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - ORDI-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - ACE-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - LPT-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - USTC-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - AMB-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - IOST-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - ICP-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - SUI-EUR (2000 hours)\n",
      "✅ Data successfully fetched: binance - ETH-TUSD (2000 hours)\n",
      "✅ Data successfully fetched: binance - IOTX-ETH (2000 hours)\n",
      "✅ Data successfully fetched: binance - WBETH-ETH (2000 hours)\n",
      "✅ Data successfully fetched: binance - EOS-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - ONT-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - STG-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - ACH-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - ONGAS-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - MAV-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - FIDA-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - GMX-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - BTC-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - GAS-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - RARE-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - SUN-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - ETC-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - BONK-FDUSD (2000 hours)\n",
      "✅ Data successfully fetched: binance - BTC-RON (2000 hours)\n",
      "✅ Data successfully fetched: binance - DOGE-FDUSD (2000 hours)\n",
      "✅ Data successfully fetched: binance - NEAR-ETH (2000 hours)\n",
      "✅ Data successfully fetched: binance - NANO-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - SKL-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - CYBER-FDUSD (2000 hours)\n",
      "✅ Data successfully fetched: binance - PYR-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - ADA-FDUSD (2000 hours)\n",
      "✅ Data successfully fetched: binance - FORTH-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - ATOM-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - AVAX-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - ATOM-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - HIVE-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - WLD-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - FIS-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - GNS-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - USDT-RON (2000 hours)\n",
      "✅ Data successfully fetched: binance - HOOK-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - SYS-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - ACH-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - YFI-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - GMT-EUR (2000 hours)\n",
      "✅ Data successfully fetched: binance - APT-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - ORDI-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - MKR-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - SOL-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - DENT-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - TWT-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - ACA-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - RIF-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - AUCTION-FDUSD (2000 hours)\n",
      "✅ Data successfully fetched: binance - BNB-TUSD (2000 hours)\n",
      "✅ Data successfully fetched: binance - INJ-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - AERGO-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - LINK-EUR (2000 hours)\n",
      "✅ Data successfully fetched: binance - 1000SATS-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - RAY-BNB (2000 hours)\n",
      "✅ Data successfully fetched: binance - ALICE-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - ARK-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - AVAX-USDC (2000 hours)\n",
      "✅ Data successfully fetched: binance - AVAX-BRL (2000 hours)\n",
      "✅ Data successfully fetched: binance - HBAR-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - ALT-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - RONIN-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - POND-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - BLUR-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - XLM-ETH (2000 hours)\n",
      "✅ Data successfully fetched: binance - ETH-PLN (2000 hours)\n",
      "✅ Data successfully fetched: binance - OP-ETH (2000 hours)\n",
      "✅ Data successfully fetched: binance - USDT-ARS (2000 hours)\n",
      "✅ Data successfully fetched: binance - ENS-FDUSD (2000 hours)\n",
      "✅ Data successfully fetched: binance - LUNA-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - VET-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - ARB-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - BICO-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - ATM-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - ANKR-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - VANRY-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - SANTOS-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - XAI-FDUSD (2000 hours)\n",
      "✅ Data successfully fetched: binance - LQTY-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - CHR-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - STEEM-ETH (2000 hours)\n",
      "✅ Data successfully fetched: binance - FLOW-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - ARB-ETH (2000 hours)\n",
      "✅ Data successfully fetched: binance - BTC-FDUSD (2000 hours)\n",
      "✅ Data successfully fetched: binance - ILV-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - XRP-FDUSD (2000 hours)\n",
      "✅ Data successfully fetched: binance - ICP-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - LDO-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - AMP-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - MEME-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - FLM-BTC (2000 hours)\n",
      "✅ Data successfully fetched: binance - GRT-EUR (2000 hours)\n",
      "✅ Data successfully fetched: binance - SUPER-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - LUNA-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - ARB-TUSD (2000 hours)\n",
      "✅ Data successfully fetched: binance - ALGO-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - BEL-USDT (2000 hours)\n",
      "✅ Data successfully fetched: binance - SLP-TRY (2000 hours)\n",
      "✅ Data successfully fetched: binance - BTC-UAH (2000 hours)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 29\u001b[0m\n\u001b[0;32m     17\u001b[0m instrument \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstrument\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     19\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarket\u001b[39m\u001b[38;5;124m\"\u001b[39m: market,\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstrument\u001b[39m\u001b[38;5;124m\"\u001b[39m: instrument,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJSON\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m }\n\u001b[1;32m---> 29\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url_spot_volume, headers\u001b[38;5;241m=\u001b[39mheaders, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m     32\u001b[0m     json_response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32mc:\\Users\\YuweiCao\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\YuweiCao\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\YuweiCao\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\YuweiCao\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:746\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    743\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 746\u001b[0m     r\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mc:\\Users\\YuweiCao\\anaconda3\\Lib\\site-packages\\requests\\models.py:902\u001b[0m, in \u001b[0;36mResponse.content\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    900\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    901\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 902\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_content(CONTENT_CHUNK_SIZE)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    905\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\YuweiCao\\anaconda3\\Lib\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\YuweiCao\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:1057\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m-> 1057\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\YuweiCao\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:1209\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1208\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1209\u001b[0m chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_chunk(amt)\n\u001b[0;32m   1210\u001b[0m decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(\n\u001b[0;32m   1211\u001b[0m     chunk, decode_content\u001b[38;5;241m=\u001b[39mdecode_content, flush_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m )\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoded:\n",
      "File \u001b[1;32mc:\\Users\\YuweiCao\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:1146\u001b[0m, in \u001b[0;36mHTTPResponse._handle_chunk\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left:\n\u001b[1;32m-> 1146\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39m_safe_read(amt)  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m-\u001b[39m amt\n\u001b[0;32m   1148\u001b[0m     returned_chunk \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[1;32mc:\\Users\\YuweiCao\\anaconda3\\Lib\\http\\client.py:640\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[0;32m    634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[0;32m    635\u001b[0m \n\u001b[0;32m    636\u001b[0m \u001b[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 640\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[0;32m    642\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n",
      "File \u001b[1;32mc:\\Users\\YuweiCao\\anaconda3\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\YuweiCao\\anaconda3\\Lib\\ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\YuweiCao\\anaconda3\\Lib\\ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "instrument_filepath = \"C:/Users/YuweiCao/Documents/GitHub/Project/Project/spot_volume/result/crypto_instruments.csv\"\n",
    "instruments_df = pd.read_csv(instrument_filepath)\n",
    "\n",
    "url_spot_volume = 'https://data-api.cryptocompare.com/spot/v1/historical/hours'\n",
    "headers = {\"Content-type\": \"application/json\", \"authorization\": f\"Apikey {API_KEY}\"}\n",
    "\n",
    "save_dir = \"C:/Users/YuweiCao/Documents/GitHub/Project/Project/spot_volume/result\"\n",
    "\n",
    "# **遍历所有交易所**\n",
    "for market in instruments_df[\"market\"].unique():\n",
    "    trade_data = []\n",
    "    \n",
    "    # **筛选当前交易所的交易对**\n",
    "    market_instruments_df = instruments_df[instruments_df[\"market\"] == market]\n",
    "\n",
    "    for _, row in market_instruments_df.iterrows():\n",
    "        instrument = row[\"instrument\"]\n",
    "        \n",
    "        params = {\n",
    "            \"market\": market,\n",
    "            \"instrument\": instrument,\n",
    "            \"limit\": 2000,  # 获取最近 2000 小时数据\n",
    "            \"aggregate\": 1,  # 每一个小时\n",
    "            \"fill\": \"true\",\n",
    "            \"apply_mapping\": \"true\",\n",
    "            \"response_format\": \"JSON\",\n",
    "        }\n",
    "\n",
    "        response = requests.get(url_spot_volume, headers=headers, params=params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            json_response = response.json()\n",
    "\n",
    "            # **检查数据是否有效**\n",
    "            if \"Data\" in json_response and isinstance(json_response[\"Data\"], list) and len(json_response[\"Data\"]) > 0:\n",
    "                for entry in json_response[\"Data\"]:  # 遍历 2000 小时数据\n",
    "                    trade_data.append({\n",
    "                        \"market\": market,\n",
    "                        \"instrument\": instrument,\n",
    "                        \"base_asset\": entry[\"BASE\"],  # 基础资产\n",
    "                        \"quote_asset\": entry[\"QUOTE\"],  # 报价资产\n",
    "                        \"time\": pd.to_datetime(entry[\"TIMESTAMP\"], unit=\"s\"),  # 转换时间\n",
    "                        \"open\": entry[\"OPEN\"],  # 开盘价\n",
    "                        \"high\": entry[\"HIGH\"],  # 最高价\n",
    "                        \"low\": entry[\"LOW\"],  # 最低价\n",
    "                        \"close\": entry[\"CLOSE\"],  # 收盘价\n",
    "                        \"total_trades\": entry[\"TOTAL_TRADES\"],  # 总交易笔数\n",
    "                        \"total_trades_buy\": entry[\"TOTAL_TRADES_BUY\"],  # 买单数\n",
    "                        \"total_trades_sell\": entry[\"TOTAL_TRADES_SELL\"],  # 卖单数\n",
    "                        \"volume\": entry[\"VOLUME\"],  # 以 base_asset 计数的交易量\n",
    "                        \"quote_volume\": entry[\"QUOTE_VOLUME\"],  # 以 quote_asset 计数的交易量\n",
    "                        \"volume_buy\": entry[\"VOLUME_BUY\"],  # 以 base_asset 计数的买单交易量\n",
    "                        \"quote_volume_buy\": entry[\"QUOTE_VOLUME_BUY\"],  # 以 quote_asset 计数的买单交易量\n",
    "                        \"volume_sell\": entry[\"VOLUME_SELL\"],  # 以 base_asset 计数的卖单交易量\n",
    "                        \"quote_volume_sell\": entry[\"QUOTE_VOLUME_SELL\"],  # 以 quote_asset 计数的卖单交易量\n",
    "                    })\n",
    "                print(f\"✅ Data successfully fetched: {market} - {instrument} ({len(json_response['Data'])} hours)\")\n",
    "            else:\n",
    "                print(f\"❌ No data for {market} - {instrument}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"❌ API request failed for {market} - {instrument}, Status Code: {response.status_code}\")\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    # **转换成 DataFrame**\n",
    "    if trade_data:\n",
    "        spot_volume_df = pd.DataFrame(trade_data)\n",
    "        \n",
    "        # **存储 CSV，按交易所划分**\n",
    "        csv_filepath = os.path.join(save_dir, f\"{market}_spot_volume_2000h.csv\")\n",
    "        spot_volume_df.to_csv(csv_filepath, index=False, encoding=\"utf-8\")\n",
    "        print(f\"📁 Data for {market} saved to {csv_filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = spot_volume_df.pivot(index=\"instrument\", columns=\"market\", values=\"total_trades\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data successfully fetched: binance - BTC-USDT (2000 hours)\n"
     ]
    }
   ],
   "source": [
    "# **选择一个交易所 & 交易对**\n",
    "market = \"binance\"\n",
    "instrument = \"BTC-USDT\"\n",
    "\n",
    "# **CryptoCompare API 端点**\n",
    "url_spot_volume = 'https://data-api.cryptocompare.com/spot/v1/historical/hours'\n",
    "headers = {\"Content-type\": \"application/json\", \"authorization\": f\"Apikey {API_KEY}\"}\n",
    "\n",
    "params = {\n",
    "    \"market\": market,\n",
    "    \"instrument\": instrument,\n",
    "    \"limit\": 2000,  # 获取最近 2000 小时数据\n",
    "    \"aggregate\": 1,  # 每一个小时\n",
    "    \"fill\": \"true\",\n",
    "    \"apply_mapping\": \"true\",\n",
    "    \"response_format\": \"JSON\",\n",
    "}\n",
    "\n",
    "response = requests.get(url_spot_volume, headers=headers, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    json_response = response.json()\n",
    "\n",
    "    # **检查数据是否有效**\n",
    "    if \"Data\" in json_response and isinstance(json_response[\"Data\"], list) and len(json_response[\"Data\"]) > 0:\n",
    "        trade_data = []\n",
    "\n",
    "        for entry in json_response[\"Data\"]:  # 遍历 2000 小时数据\n",
    "            trade_data.append({\n",
    "                \"market\": market,\n",
    "                \"instrument\": instrument,\n",
    "                \"base_asset\": entry[\"BASE\"],  # 基础资产\n",
    "                \"quote_asset\": entry[\"QUOTE\"],  # 报价资产\n",
    "                \"time\": pd.to_datetime(entry[\"TIMESTAMP\"], unit=\"s\"),  # 转换时间\n",
    "                \"open\": entry[\"OPEN\"],  # 开盘价\n",
    "                \"high\": entry[\"HIGH\"],  # 最高价\n",
    "                \"low\": entry[\"LOW\"],  # 最低价\n",
    "                \"close\": entry[\"CLOSE\"],  # 收盘价\n",
    "                \"total_trades\": entry[\"TOTAL_TRADES\"],  # 总交易笔数\n",
    "                \"total_trades_buy\": entry[\"TOTAL_TRADES_BUY\"],  # 买单数\n",
    "                \"total_trades_sell\": entry[\"TOTAL_TRADES_SELL\"],  # 卖单数\n",
    "                \"volume\": entry[\"VOLUME\"],  # 以 base_asset 计数的交易量\n",
    "                \"quote_volume\": entry[\"QUOTE_VOLUME\"],  # 以 quote_asset 计数的交易量\n",
    "                \"volume_buy\": entry[\"VOLUME_BUY\"],  # 以 base_asset 计数的买单交易量\n",
    "                \"quote_volume_buy\": entry[\"QUOTE_VOLUME_BUY\"],  # 以 quote_asset 计数的买单交易量\n",
    "                \"volume_sell\": entry[\"VOLUME_SELL\"],  # 以 base_asset 计数的卖单交易量\n",
    "                \"quote_volume_sell\": entry[\"QUOTE_VOLUME_SELL\"],  # 以 quote_asset 计数的卖单交易量\n",
    "            })\n",
    "\n",
    "        print(f\"✅ Data successfully fetched: {market} - {instrument} ({len(json_response['Data'])} hours)\")\n",
    "\n",
    "        # **转换成 DataFrame**\n",
    "        trade_volume_df = pd.DataFrame(trade_data)\n",
    "\n",
    "        # **存储 CSV**\n",
    "        save_dir = \"C:/Users/YuweiCao/Documents/GitHub/Project/Project/spot_volume/result\"\n",
    "        os.makedirs(save_dir, exist_ok=True)  # 确保文件夹存在\n",
    "        csv_filepath = os.path.join(save_dir, f\"{market}_{instrument}_spot_volume_2000h.csv\")\n",
    "        trade_volume_df.to_csv(csv_filepath, index=False, encoding=\"utf-8\")\n",
    "\n",
    "        # **显示前 10 行的数据**\n",
    "    else:\n",
    "        print(f\"❌ No data for {market} - {instrument}\")\n",
    "\n",
    "else:\n",
    "    print(f\"❌ API request failed for {market} - {instrument}, Status Code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
